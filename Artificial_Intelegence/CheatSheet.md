# 机器学习

监督学习: 我们知道正确的答案或期望的输出. 有分类和回归两种.
无监督学习: 我们不展示输出，或者达到特定输出所需的特定输入。例如: 聚类, 降维, 关联分析.
半监督学习: 同时使用有标签和无标签的数据进行训练.
自监督学习: 自动生成标签, 然后用生成的标签进行训练.

泛化 (Generalization): 模型适用于新样本的能力即泛化能力。一般而言训练样本越多越有可能通过学习获得强泛化能力的模型

假设空间 (Hypothesis)：对于当前任务，学习算法所考虑的所有可能的假设构成的空间称为假设空间，即模型可以表示的所有可能的解。

奥卡姆剃刀: 若非必要，勿增实体. 假设空间中可能有多个与训练集一致的假设，但他们对测试数据会预测出不同的结果. 学习过程中对某种类型假设的偏好称作归纳偏好. 若有多个假设与观察一致，选最简单的那个.

没有免费的午餐: 没有一种算法能在所有问题上都表现最好

概率近似正确: 学习算法能够以**高概率**在一个**接近正确**的程度上输出正确的假设.

参数模型: 强假设. 通常假设总体服从某个分布，该分布由一些参数确定。在此基础上构建的模型，有固定数量的参数。
非参数模型: 更灵活. 对于总体分布不做任何假设，只知道分布是存在的。非参数模型并不是没有参数，而是模型的参数量随着训练数据的增加而增长。

# 损失函数

## 二分类损失

### Hinge Loss

$$
\max(1 - h(x)y, 0)^p
$$

$p = 1$ 时是标准无约束 SVM; $p = 2$ 时是均方 SVM (可微).

### Log Loss

$$
\log(1 + e^{-h(x)y})
$$

逻辑回归使用这种损失函数, 由概率推出.

### Exponential Loss

$$
e^{-h(x)y}
$$

激进, 容易受噪声影响.

### 0-1 损失

$$
[\hat y_i \neq y_i]
$$

不连续和非凸的, 难以优化.

## 回归损失

### 均方损失

最小二乘.

$$
(h(x) - y)^2
$$

损失非负, 平方增长.

预测会是训练数据的概率均值.

### 绝对值损失

$$
|h(x) - y|
$$

适合有噪声的数据, 这样错误数据不会像在均方损失里那样主导损失.

如果 $y$ 关于 $x$ 的概率分布是 $P(y|x)$, 则期望绝对值损失最小的预测就应当是概率中值 (中位数).

### Huber Loss

平滑绝对值损失, 一阶可微.

$$
\frac 12 (h(x) - y)^2 (|h(x) - y| < \delta)\\
\delta(|h(x) - y| - \frac \delta 2) \delta (|h(x) - y| \geq \delta)
$$

绝对值损失和均方损失的组合.

### Log-Cosh Loss

$$
\log \text{cosh}(h(x) - y)\\
\text{cosh}(x) = \frac{e^x - e^{-x}}{2}
$$

有渐近线, 在偏差大的时候呈现线性的趋势, 在零点附近平滑. 处处无限次可微.

# 正则项

过拟合: 小数据量 + 复杂模型

模型的复杂度: 参数量, 参数大小.

正则项是用来通过降低模型复杂度来缓解过拟合的.

参数过大会导致更大的惩罚, 当参数变成 $0$ 的时候, 我们也可以认为删去了一个参数.

## 范数

$l_p$ 范数定义为:

$$
||w||_p = (\sum w_i^p)^{\frac 1p}
$$

即 $w$ 到原点的 Minkowski 距离.

## 弹性网络

$$
\alpha ||w||_1 + (1 - \alpha) ||w||_2^2
$$

是 $l_1$ 和 $l_2^2$ 的组合. 严格凸, 不可微.

## 稀疏解和稠密解

稀疏解: 存在更少的非零参数.

当 $p > 1$ 的时候, 小的分量惩罚非常小, 所以是鼓励小分量不等于 $0$ 的, 但是当 $p \leq 1$ 的时候, 小分量在接近 $0$ 的时候梯度更大, 鼓励小分量被 $0$ 处的黑洞吸入.

但是 $p \leq 1$ 的情况是非凸的 (凸的好处: 局部最优就是全局最优, 梯度下降/牛顿迭代收敛稳定高效), 所以弹性网络通过叠加 $l_2^2$ 引入凸性.

## $\lambda$

选择 $\lambda$ 的大小, 可以通过验证集上的表现来调参.

Telescopic 搜索. 先找 $\lambda$ 的数量级, 再找附近更优的值. (减少枚举)

## 早停

调整迭代次数, 防止过拟合.

# 监督学习

## 混淆矩阵

||$\hat y = 1$| $\hat y = 0$ |
|-|-|-|
|$y = 1$|TP|FN| 
|$y = 0$|FP|TN| 

查准率: $\frac {TP}{TP + FP}$
查全率: $\frac {TP}{TP + FN}$

## 训练, 验证, 测试

有时候用测试集验证. (反正也不会从验证集学习)

按时间先后划分训练集和测试集可以让模型学习过去的模式来解决未来的问题. 否则最好均匀随机分割, 保证两个数据集的分布相同.

留出法: 训练集和测试集互斥
交叉验证法: 分成 $k$ 个互斥子集, 每次用一个子集做测试集, 剩下的 $k - 1$ 个做训练集.
自助法: 有放回随机抽样.

## 生成-判别

可以认为监督学习是在估计 $P(X, Y)$, 当认为 $P(X, Y) = P(X|Y)P(Y)$ 时, 称为生成学习, 否则直接估计 $P(X, Y)$ 即为判别学习.

# k-NN

假设: 相似的输入有相似的输出.

对于一个 $x_*$ 在 $k$ 个最相似的 $x$ 中选择 (出现最多的标签/标签的平均值).

也可以按距离给 $k$ 个邻居加权.

$k$ 大了欠拟合, 小了过拟合.

## Minkowski 距离

$$
\left (\sum_{r = 1}^d |x_r - z_r|^p \right )^{\frac 1p}
$$

$p = 1$ 时, 即为曼哈顿距离, $p = 2$ 时即为欧氏距离, $p \to \infin$ 时即为切比雪夫距离.

## Hamming 距离

$$
\frac 1n \sum_{i} [x_i \neq y_i]
$$

即二进制串异或后 $1$ 的数量 (的均值).

## 余弦相似度

余弦越大, 指向越相同; 余弦趋于 $0$, 指向垂直; 余弦越小, 指向越相反.

$$
cos \left <A, B\right > = \frac {A * B}{|A||B|}
$$

## 贝叶斯最优分类器

假设知道了所有 $x$, $y$ 的分布 $P(y|x)$. 那么预测 $\hat y$ 就是 $\argmax_y P(y|x^*)$.

那么错误率就是当 $\hat y \neq y^x$ 的概率, 也就是 $1 - P(\hat y|x^*)$.

### 1-NN

当样本数 $n \to \infin$, 类别数 $m = 2$ 时, 1-NN 错误率不大于贝叶斯最优分类器的两倍.

由于 $n \to \infin$, $x^*$ 和 $x$ 同分布, 所以存在足够多的 $(x_i, y_i)$ 满足 $x_i = x^*$. 而且成为最近邻的机会, 即输出的分布有 $P(\hat y | x^*) = P(y^* | x^*)$.

1nn的错误率为: $P(y_0 | x^*)(1 - P(\hat y_0 | x^*)) + (1 - P(\hat y_1 | x^*))P(\hat y_1 | x^*)$, 也就是 $2P(y_0 | x^*)(1 - P(y_0 | x^*)) \leq 2P(y^* | x^*)$.

课件没说是二分类, 耽误了我好久.

## 维度灾难

维度特别大时, 对于随机分布于边长为 $1$ 的超立方体中的数据点, 包含一个点和它最近的 $k$ 个邻居的最小超立方体会越来越趋近于全体数据分布的大超立方体; 随机分布的点对之间的距离越来越趋近于一个由维度数决定的常数.

高维数据一般会先降维处理.

## 约简

类似于剪枝, 将数据中的*类离群点*删除, 剩余的数据分为原型和吸收点, 保留原型, 删除吸收点, 可以减小模型规模.

类离群点的寻找可以给出一个阈值 $r < k$, 如果一个点的 $k$ 近邻中有大于等于 $r$ 个和它不在同一个类别, 则删除之.

## KD-Tree

每次选择一维 Feature, 将数据分成两半. 剪枝 k-NN 的搜索.

## Ball-Tree

每次选择集合内距离最远的两个点 $x_1, x_2$, 把剩下的点投影到线段 $x_1x_2$ 上排序 (不改变点的坐标, 只是排序), 然后平均分成两半.

每个节点有一个极小的超球包含所有点. 超球的球心是重心.

# 感知机

假设: 二分类, 线性可分.

求一个超平面: $w^Tx + b = 0$, 将空间中的点分成两类.

为了处理偏置项, 增加一维, 令 $x$ 在这个维度上固定为 $1$, 则这个维度上的 $w$ 值就相当于 $b$, 即对增加维度后的 $x$ 只需要学习 $w$, 得到过原点的超平面 $wx = 0$ 即可.

记两类的 $y$ 分别为 ${+1, -1}$, 那么我们认为 $w^Tx > 0$ 的点的标签应当是 $1$, $w^Tx < 0$ 的点的标签应当是 $-1$.

## 迭代法

$w$ 加上一个向量相当于将平面的法向量沿增量的方向拖拽. 对于 $y = 1$, 但是 $w^Tx < 0$ 的样本, 我们希望拖拽 $w$ 所以需要 $x$; 反之对于 $y = -1$, 但是 $w^Tx > 0$ 的样本, 我们希望推开 $w$, 所以减去 $x$. 对于其他正确分类的情况, 便不需要进行更多调整.

更一般的, 只要 $yw^Tx \leq 0$, 就用 $w + yx$ 更新 $w$.

规定一个迭代次数上界, 每次遍历所有样本点, 如果所有样本点都被正确分类或到达最大迭代次数停止.

## 收敛

对于线性可分的数据, 感知机可在有限次迭代后找到一个可分离两个类的超平面.

假设存在一个解 $w^*$. 不失一般性, 将所有数据点缩放到单位超球内, 然后将 $w^*$ 标准化. 定义 Margin $\gamma = \min_{(x_i, y_i)\in D} |x_i^T w^*|$. 也就是距离超平面最近的点的距离.

这时断言: 感知机最多出现 $\frac 1{\gamma^2}$ 次错误.

证明: 对于 $w$ 到 $w + yx$ 的一次更新, 有 $y(w^Tx) \leq 0$, 不然不更新, 还有 $y({w^*}^Tx) > 0$, 因为 $w^*$ 是一个解.

$$
{(w+yx)}^Tw^* - w^Tw^* = yx^T w^* > 0
$$

又因为 $\gamma$ 的定义, 有 $|{(w+yx)}^Tw^* - w^Tw^*| \geq \gamma$. 即每次更新 $w^Tw^*$ 至少增加 $\gamma$.

$$
{(w+yx)}^T(w+yx) - w^Tw = 2yw^Tx + y^2x^Tx = 2yw^Tx + |x|^2 \leq |x|^2 \leq 1
$$

所以每次更新 ${(w+yx)}^T(w+yx)$ 最多增加 $1$. 假设做了 $M$ 次更新, $M\gamma \leq w^Tw^* \leq |w| = \sqrt{w^Tw} \leq \sqrt M$, 因此 $\gamma \leq \frac 1{\sqrt M}$, 得到: $M \leq \frac 1{\gamma^2}$ 

如果不缩放, 记 $\alpha = \max |x|$, 则有 $M \leq {(\frac 1{\alpha})}^2$.

## 思考

其实感知机的训练过程可以认为是梯度下降的过程. 考虑损失函数为: $\min{\left(0,-yw^Tx\right)}$ 如果正确分类就是 $0$, 否则损失就是点到超平面的距离 $|w^Tx|$, 关于 $w$ 的梯度就是 $x$. 所以减去梯度 $x$.

# 支持向量机 (SVM)

线性二分类器. 感知机的扩展, 可以找到距离最近的点最远的超平面.

点 $x$ 到超平面的距离是 $\alpha |w|$, 其中 $\alpha = \frac {w^Tx + b}{w^Tw}$. 所以有 $|d| = \frac {|w^Tx + b|}{|w|}$. 这个值是不随 $w, b$ 等比例放缩而改变的. (显然, $w, b$ 等比例放缩不会改变超平面, 也自然不会改变点到超平面的距离) 令 $\gamma(w,b) = \min_{x} d$.

我们需要求一组 $w$, 使得 $\gamma(w,b)$ 最大, 即为:

$$
\argmax_{w,b} \min_{x} \frac {|w^Tx + b|}{|w|}\\
= \argmax_{w,b} \frac 1{|w|} \min_{x} |w^Tx + b|\\
y(w^Tx + b) \geq 0
$$

不失一般性, 等比例缩放 $w, b$, 使得, $\min|w^Tx + b| = 1$. 则原式变成: $\argmax_{w,b} \frac 1{|w|} = \argmin_{w,b} w^Tw$. 也就是令 $w$ 的模长尽可能小. 把正确性的约束和最小间隔的约束合并, 得到新的约束:

$$
\argmin_{w,b} w^Tw\\
y(w^Tx + b) \geq 1
$$

目标是二次的, 约束条件都是线性的. 可以用 QCQP (Quadratic Constrained Quadratic Program) 求解器来有效地求解. 对于满足 $y(w^Tx + b) \geq 1$ 的 $x$, 称之为 "支持向量", 支持向量移动或改变会导致 SVM 改变.

## 软间隔 SVM

允许错误分类的出现, 给错误样本惩罚, 对于正确的样本保持之前的约束.

$$
\argmin_{w,b} w^Tw + C\sum \xi_i\\
y(w^Tx + b) \geq 1 - \xi_i (\xi_i \geq 0)
$$

这个惩罚是线性的, 更符合我们对错误的容忍程度.

因为有了 $\xi$, 第二行的约束就没必要存在了:

$$
\argmin_{w,b} w^Tw + C\sum \max(0, 1 - y(w^Tx + b))\\
$$

可以梯度下降.

## 核化

带约束软间隔 SVM:

$$
\argmin_{w,b} w^Tw + C\sum \xi\\
y(w^Tx + b) \geq 1 - \xi\\
\xi \geq 0\\
$$

加入拉格朗日乘子 $\alpha$, KKT 条件共有四种:

### 可行性

$$
1 - \xi - y(w^Tx + b) \leq 0\\
-\xi \leq 0
$$

### 梯度条件(最优性)

$$
\nabla (w^Tw + C\sum \xi) + \sum \alpha_i \nabla(1 - \xi_i - y_i(w^Tx_i + b)) - \sum \mu_i \nabla \xi_i = 0\\
$$

对 $w$, $b$, $\xi$ 分别求偏导, 让他们都为 $0$.

$$
w = \sum \alpha_i y_ix_i\\
0 = \sum \alpha_i y_i
C = \alpha_i + \mu_i
$$

### 互补松弛

$$
\alpha_i(1 - \xi_i - y_i(w^Tx_i + b)) = 0\\
\mu_i \xi_i = 0
$$

### 乘子非负

$$
\alpha_i \geq 0\\
\mu_i \geq 0
$$

结合前面的 $C = \alpha_i + \mu_i$, 得到 $0 \leq \alpha_i \leq C$. 三条约束变成这一条.

### 对偶问题

综合梯度条件, 互补松弛, 乘子非负三种约束, 我们可以省略掉可行性条件. 这是因为, $\xi$ 本身也不是有规定值的变量, 我们已经将它对损失值的贡献编码到了梯度里, 也就是通过梯度条件 $C = \alpha_i + \mu_i$ 令**它决定的损失值**尽可能小.

对于 $\xi$ 的值具体的取值, 其实不重要. After all, $\xi$ 的存在是为了过滤掉小于 $0$ 的 $1 - y_i(w^Tx_i + b)$ 提供的反向损失值. 这部分在拉格朗日函数中的体现是: 当 $y_i(w^Tx_i + b) \geq 1$ 的时候, $\alpha_i$ 因为互补松弛为 $0$ 了, 也就实现了**不惩罚**. 剩下的情况, $y_i(w^Tx_i + b) < 1$, $\alpha$ 不一定是 $0$, 所以就存在一定的损失值.

对于 $\mu$, 它的存在令 $\xi_i$ 在拉格朗日函数中的总系数等于 $C - \alpha_i - \mu_i = 0$, 使得 $\xi$ 真正变成形式变量, 不对损失函数有任何贡献, 而是完全由 $1 - y_i(w^Tx_i + b)$ 来提供损失. 这也是为什么我们最后求解的时候不需要关注 $\mu$. 学习的过程就是在 $[0, C]$ 之间插一个板, 一侧是 $\alpha$, 另一侧是 $\mu$, 其中, $\alpha$ 的一侧是含 $1 - y_i(w^Tx_i + b)$ 的, 另一侧不含 $1 - y_i(w^Tx_i + b)$.

整理对偶问题的约束式子:

$$
w = \sum \alpha_i y_ix_i\\
0 = \sum \alpha_i y_i
\alpha_i(1 - \xi_i - y_i(w^Tx_i + b)) = 0\\
\mu_i \xi_i = 0\\
0 \leq \alpha_i \leq C
$$

并且由于 $\xi$ 已经不产生贡献了, 所以在拉格朗日函数中将其消去, 将 $w$ 值代入到互补松弛的式子中, 最后把 $\sum \alpha_i y_i = 0$ 代入消去 $b$:

$$
\frac 12 w^Tw + \sum \alpha_i (1 - y_i(w^Tx_i + b))\\
\sum_{i, j} \alpha_i \alpha_j y_i y_j x_i^T x_j + \sum_{i} \alpha_i 1 - y_i(\sum \alpha_j y_jx_j^Tx_i + b)\\
\sum_{i, j} \alpha_i \alpha_j y_i y_j x_i^T x_j - \alpha_i \alpha_j  y_i y_jx_j^Tx_i + \sum_i \alpha_i (1 - y_i b)
-\frac 12 \sum_{i, j} \alpha_i \alpha_j y_i y_j x_i^T x_j + \sum_i \alpha_i (1 - y_i b)
-\frac 12 \sum_{i, j} \alpha_i \alpha_j y_i y_j x_i^T x_j + \sum_i \alpha_i
$$

注意, 现在我们操作的式子一直都是拉格朗日函数而不是原来意义的损失函数. 而拉格朗日函数由两种参数, 原参数 $w, b$ 和拉格朗日乘子 $\alpha, \mu$. 我们的取极值也需要在这些维度上进行分类讨论.

拉格朗日乘子法认为, 只有拉格朗日函数在拉格朗日乘子 $\alpha, \mu$ 上取极大值的时候, 原函数满足约束条件; 满足约束的基础上, 并且在原参数 $w$ 上取得极小值的时候, 这时拉格朗日函数取得原函数的极小值. 在之前的梯度条件中, 已经用 $\alpha, \mu$ 表达了 $w$ 和 $b$, 写出了令拉格朗日函数在 $w, b$ 上取极小值的表达式. 接下来, 需要对拉格朗日函数上在 $\alpha, \mu$ 上取极大值, 使其满足约束, 也就是令其相反数取极小值.

整理出对偶问题的最终形式:

$$
\argmin_{\alpha} \frac 12 \sum_{i, j} \alpha_i \alpha_j y_i y_j x_i^T x_j - \sum_i \alpha_i\\
\sum \alpha_i y_i = 0\\
0 \leq \alpha_i \leq C
$$

发现没有对 $b$ 进行求解, 因为 $b$ 被约掉了 (系数为 $0$), 但是 $b$ 在核化的问题中的意义是不变的, 所以可以求出 $\alpha$ 之后, 用支持向量重新求 $b$:

$$
y_i(\sum y_j\alpha_j x_j^T x_i + b) = 1\\
b = \frac 1{y_i} - \sum y_j\alpha_j x_j^T x_i\\
b = y_i - \sum y_j\alpha_j x_j^T x_i\\
$$

### 加权和

审视训练出的分类器:

$$
h(x) = \sum \alpha_i y_i x_i^T x + b
$$

发现答案是 $y$ 的加权和加上一个偏移. 权值则是 $\alpha x_i^T x$, 可以认为是它们的距离. 所以 SVM 核化后可以理解为加权的 kNN. ($k = n$, 如果选择核函数为 RBF 核, 则指数衰减会让绝大多数训练样本几乎没有权重)

### 训练

为了满足 $\sum \alpha_i y_i = 0$ 的约束, 不能每次只更新一个 $\alpha$, 也不能直接梯度下降, SMO 算法每次更新两个 $\alpha$, 这样就可以保持约束的前提下对 $\alpha$ 进行调整.

# 概率估计

## MLE (最大似然估计)

目标: 似然函数最大.

先对数据的分布做假设, 考虑在假设中, 训练数据 $D$ 出现的概率. 我们希望找到让 $D$ 出现的概率最大的分布参数 $\theta$. 如果所有样本都是独立同分布的, 那么整个训练数据出现的概率应该是它们的乘积.

令概率的乘积最大也就是令概率的对数的总和最大. 我们对这个似然函数进行求导, 然后令其等于 $0$ 即可找到 $\theta$.

## MAP (最大后验估计)

### Beta 分布

$$
P(\theta) = \frac{\theta^{\alpha - 1}(1 - \theta)^{\beta - 1}}{B(\alpha, \beta)}
$$

其中 $B(\alpha, \beta)$ 是 Beta 函数, 确保了 $P$ 的积分为 $1$:

$$
B(\alpha, \beta) = \frac{\Gamma (\alpha) \Gamma (\beta)}{\Gamma (\alpha + \beta)}
$$

$\Gamma (z)$ 是 Gamma 函数, 可以感性理解为是 $(z - 1)!$ 的插值.

### MAP

我们对于 $\theta$ 的先验认识是 Beta 分布. MAP 需要做的是基于训练数据 $D$, 选择一个最有可能的 $\hat \theta$ 作为后验估计.

由于 $P(\theta | D) = \frac{P(D|\theta)P(\theta)}{P(D)}$, $D$ 已经出现了, 可以认为是 $1$, 所以令 $P(\theta | D)$ 最大, 就是令 $\log P(\theta | D)$ 最大, 就是令 $\log P(D|\theta) + \log P(\theta)$ 最大:

$$
\arg \max_{\theta} \log P(D|\theta) + \log P(\theta)\\
= \arg \max_{\theta} \sum_{x \in D} \log P(X|\theta) + (\alpha - 1) \log \theta + (\beta - 1) \log (1 - \theta)
$$

当样本足够多, $\hat \theta_{MAP} \to \hat \theta_{MLE}$. 如果样本较少, 那么 MAP 的可靠性更大程度上取决于先验.

本质上 MAP 是添加了正则项的 MLE.

## 二项分布的特化

$$
\arg \max_{\theta} \sum_{x \in D} \log P(X|\theta)\\
= \arg \max_{\theta} n_1 \log \theta + n_0 \log \theta\\
\arg \max_{\theta} \log P(D|\theta) + \log P(\theta)\\
= \arg \max_{\theta} (n_1 + \alpha - 1) \log \theta + (n_0 + \beta - 1) \log \theta\\
$$

在 MLE 中, $\theta$ 的闭式解是 $\frac {n_1}{n}$, 在 MAP 中是 $\frac {n_1 + \alpha - 1}{n + \beta + \alpha - 2}$.

# 朴素贝叶斯

假设: feature 互相独立.

则 $P(x|y) = \prod P(x_i|y)$.

朴素贝叶斯分类器是一个线性分类器, 感性理解就是由于它假设特征独立, 所以它是没法解决异或问题的.

最大化 $D$ 中每对 $(x, y)$ 出现的概率的乘积, 也就是最大化概率对数的总和.

$$
\arg \max_y P(y|x)\\
= \arg \max_y P(x|y)P(y)\\
= \arg \max_y \sum \log P(x_i|y) + \log P(y)\\
$$

接着就可以用训练数据来拟合后验分布了, 其中 $K_{\alpha}$ 表示特征 $\alpha$ 的类别数量:

$$
[\theta_{jc}]_\alpha = \frac{\sum [y_i == c] * [x_{i\alpha} == j] + l}{\sum [y_i == c] + lK_{\alpha}}\\
pi_{c} = \frac{n_c}{n}
$$

平滑参数 $l = 0$ 的时候, 我们相当于对每个取值建立了 MLE 估计器. 当 $l = 1$ 时, 即为拉普拉斯平滑.

预测时, 只需令各个 feature 的后验概率尽可能大即可:

$$
h(x) = \arg \max_y \prod P(x_\alpha|y)P(y)\\
\arg \max_y \prod [\theta_{jy}]_\alpha \frac {\sum {y_i = y}}n\\
$$

## 推广到整数特征

用多项分布代替二项分布:

令 $m = \sum x_i$, 则:

$$
P(x|m,y) = \frac {m!\prod (\theta_{ic})^{x_i}}{\prod x_i!}\\
\theta_{\alpha c} = \frac{\sum [y == c]x_{i\alpha} + l}{\sum [y == c]m_i + ld}
$$

预测:

$$
h(x) = \arg \max_y \prod P(x_\alpha|y)P(y)\\
= \arg \max_y \prod \theta_{jy}^{x_\alpha} \frac {\sum {y_i = y}}n\\
$$

如果是二分类, 则:

$$
[w]_\alpha =  \log \theta_{\alpha +} - \log \theta_{\alpha -}\\
b =  \log \pi_{+} - \log \pi_{-}\\
$$

则 $w^Tx + b > 0$ 时预测 $y = +$, 否则 $y = -$. 这证明了朴素贝叶斯分类器是线性分类器.

![alt text](image.png)

## 推广到连续特征

使用高斯分布:

$$
P(x_\alpha|y) = \frac 1{\sqrt{2\pi}\sigma_{\alpha c}} e^{-\frac 12(\frac{x_\alpha - \mu_{\alpha c}}{\sigma_{\alpha c}})^2}\\
\mu_{\alpha c} = \frac {\sum [y_i == c]x_{i\alpha}}{n_c}\\
\sigma^2_{\alpha c} = \frac {\sum [y_i == c](x_{i\alpha} - \mu_{\alpha c})^2}{n_c}\\
$$

将每一维合起来, 得到总的高维高斯分布的参数 $\mu_c$ 和 $\Sigma_c$, $\mu_c$ 的分量就是 $\mu_{\alpha c}$; 而协方差矩阵 $\Sigma_c$ 是一个对角矩阵, 对角线元素是 $\sigma^2_{\alpha c}$, 剩下的元素全是 $0$, 这是因为假设了所有特征互相独立.

预测的式子和上面原理相同, 都是用贝叶斯公式推出 $P(y|x)$.

## 逻辑回归

对于二分类问题, 高斯朴素贝叶斯本质上是逻辑回归.

![alt text](image-1.png)

高斯朴素贝叶斯二分类器的决策边界:

$$
\log \frac {P(+|x)}{P(-|x)} = w^Tx + b\\
\frac {P(+|x)}{P(-|x)} = e^{w^Tx + b}\\
\frac {P(+|x)}{1 - P(+|x)} = e^{w^Tx + b}\\
P(+|x) = e^{w^Tx + b}(1 - P(+|x))\\
P(+|x) = \frac{e^{w^Tx + b}}{1 + e^{w^Tx + b}}\\
P(+|x) = \frac{1}{1 + e^{-w^Tx - b}}\\
P(-|x) = \frac{1}{1 + e^{w^Tx + b}}\\
P(y|x) = \frac{1}{1 + e^{y(w^Tx + b)}}\\
$$

$P(y|x)$ 的形式符合 sigmoid 函数.

我们需要得到 $P(y|x)$ 的参数 $w$, $b$, 仍然是增加一维, 吸收掉 $b$. 如果用 MLE 估计, 则:

$$
w = \argmin_w \sum \log{(1 + e^{-y_iw^Tx_i})}
$$

直接令梯度为 $0$ 难以求出闭式解, 所以进行梯度下降.

在 MAP 中, 假设 $w$ 的先验为 $n$ 元标准正态分布, 加入正则项:

$$
w = \argmin_w \sum \log{(1 + e^{-y_iw^Tx_i})} + \lambda w^Tw
$$

同样没有闭式解, 需要梯度下降.

与生成算法朴素贝叶斯直接求出闭式解之后计算出 $P(y)P(x|y)$ 不同, 逻辑回归是判别算法.

# 梯度下降

## 梯度

泰勒展开的一次项是梯度, 二次项是 Hessian 矩阵.

$$
l(w + s) \approx l(w) + s^Tg(w) + \frac 12 s^TH(w)s
$$

## AdaGrad

对每个特征单独计算偏导数 $g_i$, 然后对每个特征记录历史偏导数的平方和 $z_i = \sum_{j = 1}^k g_i^2$, 则本次学习率就是 $\frac{\eta g_i}{\sqrt z_i + \epsilon}$. 学习率单调下降, 符合一般梯度下降的规律. (收敛之前步长小)

## 牛顿迭代

考虑泰勒展开后的结果达到局部最优值, 则 $s^T$ 的系数为 $0$.

$$
g(w) + H(w)s = 0\\
s = -g(w)(H(w))^{-1}\\
w^* = w - (H(w))^{-1}g(w)
$$

二次收敛, 对于二次以内的函数, 一步收敛 (得到闭式解).

优化: 只计算 $H(w)$ 的对角线项, 减小学习率, 本质上 mix 了牛顿迭代和梯度下降.

优化: 可以先做梯度下降, 接近局部最优后用牛顿迭代. (可以防止牛顿迭代发散)

## BGD-SGD-MSGD

BGD 批量梯度下降: 对所有样本求梯度. 单次开销大, 收敛次数少.

SGD 随机梯度下降: 随机对每个样本单独求梯度更新权重. 单次开销小, 收敛次数多.

MSGD 小批量梯度下降: 随机选择一个 Batch 求梯度更新权重. 总体效率优于 BGD 和 SGD.

# 经验风险最小化 (ERM)

一般化无约束 SVM 的式子:

$$
\argmin_{w,b} w^Tw + C\sum \max(0, 1 - y(w^Tx + b))\\
\argmin_{w} \frac 1n \sum l(h_w(x_i), y_i) + \lambda r(w)\\
$$

定义 $h_w$ 的风险 $R(h)$ 为损失函数的期望, 理论上不可计算 (因为我们不知道 $(x, y)$ 的联合概率分布), 但是可以用训练集上的损失函数作为经验风险. 经验风险最小化就是要求 $h$:

$$
\argmin_h R(h)
$$

# 期望分析

假设一个 $x$ 对应的 $y$ 并不唯一, 而是一个分布.

训练数据 $D$ 是在某个分布中采样的, 我们用 $D$ 训练了一个符合 $D$ 分布的学习器 $h_D$. 假设存在用全体分布训练的学习器 $\overline h$ (显然是不存在的).

计算 $h_D$ 在同分布下采样的训练数据 $(x, y)$ 上的损失 (下面以均方损失为例):

$$
\begin{aligned}
&E_{x, y, D}(h_D(x) - y)^2\\
= &E_{x, y, D}(h_D(x) - \overline h(x) + \overline h(x) - y)^2\\
= &E_{x, D}(h_D(x) - \overline h(x))^2 + 2E_{x, y, D} (h_D(x) - \overline h(x))(\overline h(x) - y) + E_{x, y}(\overline h(x) - y)^2\\
= &E_{x, D}(h_D(x) - \overline h(x))^2 + 2E_{x, y} (\overline h(x) - \overline h(x))(\overline h(x) - y) + E_{x, y}(\overline h(x) - y)^2\\
= &E_{x, D}(h_D(x) - \overline h(x))^2 + E_{x, y}(\overline h(x) - y)^2\\
= &E_{x, D}(h_D(x) - \overline h(x))^2 + E_{x, y}(\overline h(x) - \overline y(x) + \overline y(x) - y)^2\\
= &E_{x, D}(h_D(x) - \overline h(x))^2 + E_{x}(\overline h(x) - \overline y(x))^2 + 2E_{x, y}(\overline h(x) - \overline y(x))(\overline y(x) - y) + E_{x, y}(\overline y(x) - y)^2\\
= &E_{x, D}(h_D(x) - \overline h(x))^2 + E_{x}(\overline h(x) - \overline y(x))^2 + 2E_{x}(\overline h(x) - \overline y(x))(\overline y(x) - \overline y(x)) + E_{x, y}(\overline y(x) - y)^2\\
= &E_{x, D}(h_D(x) - \overline h(x))^2 + E_{x}(\overline h(x) - \overline y(x))^2 + E_{x, y}(\overline y(x) - y)^2\\
\end{aligned}
$$

其中, 第一项 $h_D$ 和 $\overline h$ 的方差, 表示过拟合程度; 第二项 $\overline h$ 和 $\overline y$ 的偏差的平方, 指示了算法固有的偏差; 第三项 $\overline y$ 和 $y$ 的偏差, 表示的是固有分布的方差, 也就是噪声.

模型过拟合的时候, 方差更大; 欠拟合的时候, 偏差更大.

# 线性回归

标量 $x$ 对标量 $y$: 简单线性回归.
向量 $x$ 对标量 $y$: 多重线性回归.
向量 $x$ 对向量 $y$: 多元线性回归.

主要讨论多重线性回归, 仍然是增加一个 feature 吸收偏移 $b$.

MSE (均方误差) (最小二乘): 

$$
l(w) = \frac 1n \sum (w^Tx_i - y_i)^2 = \frac 1n (X^Tw - y)^T(X^Tw - y)
$$

让这个值的梯度为 $0$, 得到 MLE 闭式解 (最小二乘):

$$
\text{grad} (l(w)) = \frac 2n X(X^Tw - y) = 0\\
XX^Tw = Xy\\
w = (XX^T)^{-1}Xy
$$

## 岭回归

加入先验 $P(w)$ 符合 $\mu = 0$ 的多维正态分布, 求 MAP 闭式解:

$$
w = (XX^T + \lambda I)^{-1}Xy
$$

其中 $\lambda$ 的取值是 $\frac {\sigma^2}{n\tau}^2$, 其中 $\sigma$ 是 $y$ 的标准差, $\tau$ 是 $w$ 的先验标准差.

加入正则项后的线性回归又叫岭回归.

## 核化最小二乘

$$
w = (XX^T)^{-1}Xy = X\alpha\\
K^{-1}y = \alpha
$$

对于岭回归, 加入正则项, 有 $(K + \tau^2 I)^{-1}y = \alpha$.

# 核方法

对于线性不可分的数据, 可以通过升维让其在高维空间中线性可分.

高维度的计算性能差, 考虑不是学习 $w$, 而是直接学习 $w^Tx$ 这种高维度函数, 通过低维的 $x$ 输入, 直接求出高维运算的结果. (高维运算一般是点积)

在常见的损失函数中, $w$ 的梯度应当是 $x$ 的线性组合: $w = \sum \alpha_i x_i$. 所以 $w^Tx_i = \sum \alpha_j x_j^Tx_i$.

所以我们的问题就被分解成: 学习权重 $\alpha$, 快速计算 $x$ 的点积 $x_i^Tx_j$.

如果选择均方误差, 则梯度就是 $\sum 2(w^Tx_i - y_i) x_i$, $x_i$ 系数是 $\eta 2(w^Tx_i - y_i)$, 记作 $\eta \gamma_i$. 所以每次梯度下降的 $\alpha_i$ 更新为 $\alpha_i - \eta \gamma_i$. 显然 $\gamma$ 的计算也可以通过计算 $w^Tx_i + y_i = \sum \alpha_j x_j^Tx_i + y_i$ 来计算.

## 核函数

接下来的问题就只剩求点积了. 核函数 $k(x_i, x_j)$ 就是计算高维 $\phi(x_i)\phi(x_j)$ 的函数. 通常计算两两内积后, 为了防止重复计算, 我们都会放在核矩阵 $K$ 中随时取用.

在一定程度上, 核函数描述了两个输入的相似度.

### 多项式核

$$
\prod_{i = 1}^{d} (1 + x_iz_i)\\
= [1, x_1, x_2, ..., x_d, x_1x_2, ..., x_1x_2...x_d][1, z_1, z_2, ..., z_d, z_1z_2, ..., z_1z_2...z_d]^T
$$

可在 $O(d)$ 时间内计算 $O(2^d)$ 维的点积. 事实上, 多项式的指数不必选择 $d$, 较小的指数也能有不错的表现.

### 高斯核

$$
e^{-\frac{||x-z||^2}{\sigma^2}}\\
$$

对它泰勒展开之后可以得到:

$$
\sum_{i = 0}^{\infin} (\frac{||x-z||^2}{\sigma^2})^i\frac{(-1)^i}{i!}
$$

$||x-z||^2 = x^Tx + z^Tz + 2x^Tz$ 这里面有 $x$ 和 $z$ 的内积, 而这一项的次数从 $0$ 到 $\infin$. 所以可以认为存在无穷维的信息.

### 指数核

$$
e^{-\frac{||x-z||}{2\sigma^2}}\\
$$

### 拉普拉斯核

$$
e^{-\frac{|x-z|}{\sigma}}\\
$$

### Sigmoid 核

$$
\tanh(a^Tx + c)\\
\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
$$

## 条件

良定义的核函数需要满足是某些实际向量的内积, 当且仅当核矩阵是半正定的.

这两者可以互推, 因为正定的 $K$ 可以分解成 $\Phi^T\Phi$, 而对任意非零 $q$ 又可以得到 $q^T\Phi^T\Phi q \geq 0$.

## 核化

- 解 ($w$) 是 $x$ 的线性组合

- 过程中只需计算 $x$ 的内积

# 高斯过程

高斯分布:

$$
P(x;\mu, \sigma) = \frac{e^{-\frac {(x-\mu)^2}{2\sigma^2}}}{\sigma\sqrt{2\pi}}
$$

升维, 将 $x$, $\mu$ 升维至 $n$ 维向量, $\Sigma$ 升维至 $n$ 阶协方差矩阵.

$$
P(x;\mu, \Sigma) = \frac{e^{-\frac 12 ((x-\mu)^T \sigma (x-\mu))}}{|\Sigma|{2\pi}^{\frac d2}}
$$

$|\Sigma|$ 表示协方差矩阵的行列式.

## 随机过程

随着某个变量（通常是时间或空间）变化的随机变量集合

高斯过程是随机过程.

**相似的 $x$, 就有相似的 $y$**

我们认为, 我们需要的函数 $f(x)$ 对于一些输入 $x_1, x_2, ..., x_n$, 相似的 $x$ 就会得到相似的 $f(x)$.

则 $f(x_1), f(x_2), ..., f(x_n) \sim N(\mu(x), K(x,x'))$, $f(x_i)$ 和 $f(x_j)$ 的协方差, 也就是分布的相似程度, 也就是 $K(x_i, x_j)$.

对于训练数据和测试数据, 我们把它们放在同一个分布里面:

$$
\begin{bmatrix}
\mathbf{f} \\
f_*
\end{bmatrix}
\sim \mathcal{N}\left(0,
\begin{bmatrix}
K(X,X) & K(X, x_*) \\
K(x_*, X) & K(x_*, x_*)
\end{bmatrix}
\right)
$$

这是先验分布, 每个 $y$ 的均值仍然是 $0$, 只是描述了它们关于 $x$ 的区别.

接下来, 将训练输出的信息加入到模型中, 相当于锚定了在观测点上的函数值, 从而约束了观测点附近的函数值分布.

$$
\mu_* = K(x_*, X)[K(X,X) + \sigma^2 I]^{-1} y
$$

$$
\sigma_*^2 = K(x_*, x_*) - K(x_*, X)[K(X,X) + \sigma^2 I]^{-1}K(X, x_*)
$$

$\mu_*$ 的预测里, $K(x_*, X)$ 表示这一条测试输入和每个训练输入的相似度, 后面的 $y$ 应该是所有训练输出, 这里就很像根据相似度加权的平均数. 中间的矩阵 $[K(X,X) + \sigma^2 I]^{-1}$ 是根据添加噪声后的训练数据的相关性, 简单来说, 作用是减少相似度特别高的训练数据的过多的加权.

$\sigma_*^2$ 的预测则是由两部分组合而成 $K(x_*, x_*)$ 是先验方差, 后面的部分则表示从训练数据中获得的信息量, 这部分信息量越大, 结果的不确定性就越小.

协方差矩阵 $\Sigma$ 具有这些性质:

-$\Sigma_{i,i} = 0$
-$\Sigma$ 半正定

# K-means

聚类, 最小化聚类内点的 MSE:

$$
Z(C_1, C_2, ..., C_k) = \sum_{l = 1}^k \frac C2 \sum_{i,j \in C_l} ||x_i - x_j||^2
$$

设每个聚类的质心为 $\mu_i$, 则 $Z$ 还可以写成:

$$
Z(C_1, C_2, ..., C_k) = \sum_{l = 1}^k \sum_{i \in C_l} ||x_i - \mu_l||^2
$$

## Lloyd 算法

每次计算所有聚类的均值, 将每个数据点分配到最近的均值所在的聚类.

达到预定迭代次数或收敛则停止.

# 集成学习

结合多个模型的预测提高整体性能.

## Bagging

并行.

有放回地采样, 生成多个训练集, 每个训练集训练一个模型, 然后投票或平均.

目标: 降低方差. (即 $h_D$ 和 $\overline h$ 的方差)

测试误差无偏估计: 用 OOB 样本当作验证集, 估计每个模型的误差.

### 随机森林

两个优化:

建树时将训练集分成两部分, 建树集和估计标签集, 使树的结构和叶子标签分离.

留样剪枝.

## Boosting

并行, 迭代构建学习器. 输出为子学习器加权和.

每次加入一个学习器 $h_{t+1}$ 时, 评估的时 $H_t + h_{t + 1}$ 的损失最小, 而不是单独的 $h_{t + 1}$ 损失最小.

类似梯度下降地, 我们将新的损失函数泰勒展开. 对于函数的点积, 定义为在相同 $x$ 上 $y$ 的乘积的和. 这里对 $l$ 求梯度也是把函数当成是一个向量, 向量的元素就是每个 $x$ 对应的 $y$. 考虑到训练集是有限的, 所以函数也可以展开.

$$
l(H + \alpha h) = l(H) + \alpha \left<\nabla l(H), h\right>\\
\argmin_h \left<\nabla l(H), h\right>\\ 
= \argmin_h \sum \frac{\partial l}{\partial H(x_i)}h(x_i)\\ 
$$

记 $\frac{\partial l}{\partial H(x_i)} = r_i$, 只需用原来的 $H$ 求出所有 $H(x_i)$, 用这些值计算总 $l(H)$, 求偏导即可. 

通过规定 $\sum h^2(x_i) = 1$, 我们可以直接用 $-r_i$ 作为 $h$ 训练时的标签.

这就是 AnyBoost 算法.

子学习器是决策树时, 得到的就是提升树模型.

### AdaBoost

二分类. $h(x) \in \{-1, +1\}$. 指数损失函数 $l = \sum e^{-y_iH(x_i)}$.

梯度:

$$
r_i = -y_ie^{-y_iH(x_i)}
$$

归一化, 令 $Z = l$, 记归一化之后的的梯度为:

$$
w_i = \frac 1Z e^{-y_iH(x_i)}\\
\sum w_i = 1
$$

在这里 $w$ 的意义是训练样本对损失函数的贡献权重, 这也将是我们训练新学习器的采样权重. 则:

$$
h = \argmin_h w_i[h(x_i) \neq y_i]\\
\epsilon = \min w_i[h(x_i) \neq y_i]
$$

### 寻找 $\alpha$

将 $l(H + \alpha h)$ 求关于 $\alpha$ 的偏导, 令其等于 $0$.

在 AdaBoost 中, $\alpha$ 的最佳值是 $\frac 12 \ln \frac{1 - \epsilon}{\epsilon}$.

精准的步长使得 AdaBoost 的收敛速度非常快.

### 重归一化

Boosting 每次迭代, 一般是需要重新计算权重 $w$. 但是我们可以增量地计算.

未归一化的权重 $\hat w_i$ 会变成:

$$
\hat w_i * e^{-\alpha h(x_i) y_i}
$$

归一化因子 (损失函数) 会变成:

$$
2Z\sqrt{\epsilon(1 - \epsilon)}
$$

则新权重可以直接更新为:

$$
w_i \frac{e^{-\alpha h(x_i) y_i}}{2\sqrt{\epsilon(1 - \epsilon)}}
$$

### 收敛

训练损失呈指数级下降. 进行 $O(\log n)$ 次 Boost 之后训练误差为 $0$.

# 主成分分析 (PCA)

降维. 通过特征的线性组合得到新的复合特征. 通过更少的复合特征解释数据中的大部分信息.

先中心化数据. (使其均值向量为 $0$)

然后尝试找到一个单位向量, 使得所有 $x$ 沿该方向的分量方差最大, 这个单位向量的方向就是数据的第一个主成分.

$$
\argmax_{||\Phi||_2} ||\hat X^T \Phi||_2
$$

## 奇异值分解 (SVD)

将 $\hat X$ 分解为 $U\Sigma V^T$, 其中 $U$, $V$ 作为左奇异矩阵, 右奇异矩阵是列正交的, $V$ 是 $d$ 阶对角方阵, 且 $\sigma_1 \geq \sigma_2 \geq ... \geq 0$. $\sigma$ 就是奇异值.

## 主成分的提取

分解之后可以得到第一个主成分 $\Phi_1 = u_1$.

如果需要第二个主成分, 首先需要和第一个主成分正交, 而列正交的特性使得 $u_2$ 恰为 $\Phi_2$. 推广到前 $k$ 个主成分, 左奇异矩阵的前 $k$ 列的方向就是 $k$ 个主成分. 每个主成分对样本方差的贡献就是:

$$
\frac{\sigma^2}{n}
$$

为了衡量信息量, 数据的总可变性被定义为所有 feature 的总方差 (不除以 $n$) 之和, 而 $\sum \sigma^2$ 恰为这个总可变性. 这指示了如果使用全部 $d$ 个主成分, 就可以完全掌握原数据的所有信息. (这是显然的, 就相当于旋转了坐标系)

所以我们需要多少信息, 就可以选择对应的主成分, 然后用选中的 $\sigma$ 的总和占总可变性的比例来评估信息量.

## GPT 的做法

对中心化后的数据, 求两两维度的协方差矩阵 $\Sigma = \frac 1n \hat X^T \hat X$.

求协方差矩阵的特征值和特征向量.

特征值就是方差贡献, 特征向量就是主成分. 

# 线性代数相关

## 向量/矩阵求导

$$
\frac {\partial Ax}{\partial x} = A^T\\
\frac {\partial x^TA}{\partial x} = A\\
\frac {\partial A^TxB}{\partial x} = AB^T\\
\frac {\partial A^Tx^TB}{\partial x} = BA^T\\
$$

## 余子式

对于矩阵 $A$.

去掉第 $i$ 第 $j$ 列的行列式是余子式 $A_{i, j}$.

余子式乘 $(-1)^{i + j}$ 是代数余子式 $C_{i, j}$.

伴随矩阵 $A^*$ 的元素就是原矩阵的代数余子式.

用代数余子式计算行列式:

$$
|A| = \sum_{i = 1}^n a_{i, j} C_{i, j}
$$

## 正定/半正定

矩阵 $A$ 是半正定的, 当且仅当对所有非零的 $q$, 有 $q^TAq \geq 0$.

矩阵 $A$ 是正定的, 当且仅当对所有非零的 $q$, 有 $q^TAq > 0$.

### 顺序主子式

一个 $n$ 阶方阵的 $n$ 个顺序主子式是左上角方阵的行列式.

一个方阵正定, 当且仅当所有顺序主子式大于 $0$, 半正定则大于等于 $0$.

## 特征值/特征向量

定义: $Av = \lambda v$, $v$ 是特征向量, $\lambda$ 是特征值.

设 $A$ 的特征值为 $\lambda$, 则有:

$$
|A - \lambda I| = 0
$$

列方程, $1$ 元 $n$ 次方程有 $n$ 个复数解. 

$$
(A - \lambda I)v = 0
$$

代入 $\lambda$ 值, 解方程得到对应的特征向量 $v$.

## 矩阵的逆

方阵可逆当且仅当行列式不为 $0$.

$$
A^{-1} = \frac{A^*}{|A|}
$$

# 最后一节

## 基本概念与定义

### 线性分类器的异同


假设决策边界是线性的（超平面）。
形式：\$f(x) = w^T x + b\$

| 算法   | 损失函数        | 是否易过拟合 | 核心思想     |
| ---- | ----------- | ------ | -------- |
| 感知机  | 0-1 损失（不连续） | 易过拟合   | 仅关心分类正确性 |
| 逻辑回归 | 对数损失        | 较稳健    | 最大化似然概率  |
| SVM  | Hinge 损失    | 较稳健    | 最大间隔     |

### 分类与回归

**分类**：预测离散类别变量（例：是否患病）。
**回归**：预测连续变量（例：房价预测）。

### 支持向量机 (SVM)

* **定义**：寻找最优超平面，最大化类别之间的间隔（Margin）。
* **硬约束**：不允许误分类，适用于线性可分场景。
* **软约束**：允许少量误分类，通过引入松弛变量 \$\xi\$，优化目标：
  $\min \frac{1}{2} ||w||^2 + C \sum \xi_i$
* **影响**：

  * 参数 \$C\$ 控制惩罚程度：

    * \$C\$ 大：减少误分类（可能导致过拟合）。
    * \$C\$ 小：容忍误分类（可能欠拟合）。

### 过拟合与欠拟合

* **过拟合**：模型过于复杂，训练误差低但泛化能力差。

  * 易发生在特征多、样本少时。
* **欠拟合**：模型过于简单，无法捕获数据特征。
* **存在性**：监督学习和无监督学习中都可能出现过拟合问题。

### 判别式 vs 生成式模型

* **朴素贝叶斯**：生成式模型。

  * 直接建模 \$P(X|Y)\$ 和 \$P(Y)\$，计算 \$P(Y|X)\$。
* **判别式模型例子**：逻辑回归、SVM。

### 监督学习 / 无监督学习 / 强化学习

| 类型    | 定义       | 示例算法         |
| ----- | -------- | ------------ |
| 监督学习  | 有标签数据    | SVM、KNN、逻辑回归 |
| 无监督学习 | 无标签数据    | K-Means、PCA  |
| 强化学习  | 通过奖励优化策略 | Q-Learning   |

### 模型参数与系数

* 每个模型系数数量不同，例如：

  * 线性回归：\$w\$ 和 \$b\$。
  * 神经网络：各层权重和偏置。
  * SVM：\$w\$ 和 \$b\$，以及支持向量的 \$\alpha\$。

### 常见激活函数及输出范围

| 激活函数       | 输出范围    |
| ---------- | ------- |
| Sigmoid    | (0, 1)  |
| Tanh       | (-1, 1) |
| ReLU       | \[0, ∞) |
| Leaky ReLU | (-∞, ∞) |

### 模型预测变量类型

| 算法   | 预测变量类型 |
| ---- | ------ |
| 逻辑回归 | 离散变量   |
| 线性回归 | 连续变量   |

### SVM 的 Margin

* **定义**：
  $\text{Margin} = \frac{2}{||w||}$
* **单位球内最优时**：
  $\text{Margin} = 1$
  因为 \$w^T x + b = 1\$ 时满足 \$|w| = 2\$。

## 具体算法特性与比较

### 朴素贝叶斯

* **类型**：生成式模型。
* **用途**：分类问题。
* **核心假设**：特征条件独立。

### 感知机 / 贝叶斯分类器 / SVM

* 感知机和线性 SVM 是线性分类器。
* 贝叶斯分类器不是线性分类器（取决于分布）。
* **带核 SVM**：可以做非线性分类。

### 无监督学习的训练数据

* 没有标签，只包含特征。
* 典型算法：聚类（K-Means）、降维（PCA）。

### MLE 中的参数

* **错误说法**：MLE 中参数不是随机变量，而是固定的。
* 贝叶斯方法才认为参数是随机变量。

### KNN vs 线性 SVM 速度

* **预测阶段**：

  * SVM 快（仅计算超平面公式）。
  * KNN 慢（需计算全部距离）。
* **训练阶段**：KNN 无需训练，SVM 需优化超平面。

### 全贝叶斯

* **错误说法**：全贝叶斯做的是分布估计，不是点估计。
* **对应算法**：高斯过程（Gaussian Process）。

### 高斯过程

* 基于贝叶斯公式，直接对函数分布进行建模。
* 预测时输出一个均值和不确定性（置信区间）。

### 算法对数据的假设

* **正确**：所有模型对数据有隐含假设。

  * 例：线性回归假设线性关系；朴素贝叶斯假设特征独立。
* **相关理论**：No Free Lunch 定理 —— 没有一种算法适用于所有问题。